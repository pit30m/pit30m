{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515f40e0",
   "metadata": {},
   "source": [
    "# Compression Analysis\n",
    "\n",
    "Andrei's analysis on the impact of various compression parameters on file size, compression time, and PSNR.\n",
    "\n",
    "If time allows it, I will also look into decompression time but it's not high priority for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32227c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "I sampled 2,500 images from the pre-release Pit30M data, compressed **losslessly** with WebP. The images are sampled at random from 25 different driving logs and 7 cameras, covering urban areas, parks, traffic, etc., as well as a variety of weather and driving condition.\n",
    "\n",
    "The average image size is 2183KiB, computed with this handy one-liner:\n",
    "\n",
    "```bash\n",
    "find $DATASET_DIR -iname '*.webp' -exec ls -la '{}' + | \\\n",
    "    awk '{ total_b+=$5; count+=1 } END { print total_b/count/1024 }' \n",
    "```\n",
    "\n",
    "Given that this covers people*, cars*, trees, buildings, roads, etc. as seen from different view points and focal length, it should give us pretty good signal.\n",
    "\n",
    "*) In the final dataset release, faces and license plates were blurred to preserve privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff61998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=0, releaselevel='final', serial=0)\n",
      "/home/andrei/miniconda3/envs/devkit309-dev/bin/python\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.metrics as skm\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(sys.version_info)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22eb4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = Path(\"~/work/pit30m/out/size_analysis\").expanduser()\n",
    "# Limit the number of images to make the computation complete on time\n",
    "#\n",
    "# Especially SSIM computation is slow with the skimage implementation\n",
    "MAX_IMG = 2500\n",
    "\n",
    "random.seed(123)\n",
    "image_fpaths = sorted(list(DATASET_DIR.glob(\"**/*.webp\")))\n",
    "random.shuffle(image_fpaths)\n",
    "image_fpaths = image_fpaths[:MAX_IMG]\n",
    "print(len(image_fpaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75956fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images = [(fpath, Image.open(fpath)) for fpath in image_fpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███▏                         | 278/2500 [02:13<18:07,  2.04it/s, jpeg q=65 m=-1]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Default in scikit-image and in libvmaf, which means it's likely a reasonable default.\n",
    "# ffmpeg uses 8x8 windows, so close to this too. See: https://arxiv.org/pdf/2101.06354.pdf\n",
    "ssim_win_size = 11\n",
    "\n",
    "def run_configuration(all_images, format, quality, method):\n",
    "    # NOTE: For webm 'method = 4' is the default, with lower being faster\n",
    "\n",
    "    fpaths = []\n",
    "    encode_times = []\n",
    "    decode_times = []\n",
    "    psnrs = []\n",
    "    ssims = []\n",
    "    sizes_b = []\n",
    "\n",
    "    for fpath in tqdm(all_images, postfix=f\"{format} q={quality} m={method}\"):\n",
    "        image = Image.open(fpath)\n",
    "        \n",
    "        with io.BytesIO() as f:\n",
    "            start_ts = time.time()\n",
    "            if format == \"webp\":\n",
    "                image.save(f, format=format, quality=quality, method=method)\n",
    "            else:\n",
    "                # JPEG does not have 'method' to tweak encoding speed.\n",
    "                image.save(f, format=format, quality=quality)\n",
    "            encode_time = time.time() - start_ts\n",
    "            encode_times.append(encode_time)\n",
    "            n_bytes = len(f.getbuffer())\n",
    "\n",
    "            f.seek(0)\n",
    "            decode_start_ts = time.time()\n",
    "            reloaded_compressed_np = np.asarray(Image.open(f))\n",
    "            decode_time = time.time() - decode_start_ts\n",
    "            decode_times.append(decode_time)\n",
    "            original_np = np.asarray(image)\n",
    "            psnr_db = skm.peak_signal_noise_ratio(original_np, reloaded_compressed_np)\n",
    "#             print(original_np.shape)\n",
    "#             print(reloaded_compressed_np.shape)\n",
    "            # NOTE(andrei): SSIM right now is a bit slow...\n",
    "            ssim = skm.structural_similarity(original_np, reloaded_compressed_np, \n",
    "                                             win_size=ssim_win_size, channel_axis=2)\n",
    "#             ssim = -1\n",
    "\n",
    "            fpaths.append(fpath)\n",
    "            sizes_b.append(n_bytes)\n",
    "            psnrs.append(psnr_db)\n",
    "            ssims.append(ssim)\n",
    "\n",
    "#             plt.figure(figsize=(20, 8))\n",
    "#             plt.imshow(reloaded_compressed_np)\n",
    "\n",
    "    return fpaths, encode_times, decode_times, psnrs, ssims, sizes_b\n",
    "\n",
    "results = {}\n",
    "for format in [\"jpeg\", \"webp\"]:\n",
    "    for quality in [65, 70, 75, 80, 85, 90, 95, 100]:\n",
    "        meths = [-1] if format == \"jpeg\" else [0, 1, 2, 3, 4, 5, 6]\n",
    "        for method in meths:\n",
    "            results[(format, quality, method)] = \\\n",
    "                run_configuration(image_fpaths, format=format,\n",
    "                                  quality=quality, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"/home/andrei/work/pit30m/compression-blog-results-4k-2022-11-08.pkl\", \"wb\") as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ffd1e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's plot PSNR vs. quality (pretty predictible)\n",
    "# \n",
    "# Box plots would be interesting in case there's some configs which cause unexpected spread\n",
    "%matplotlib notebook\n",
    "from collections import defaultdict\n",
    "\n",
    "plot = defaultdict(lambda: defaultdict(dict))\n",
    "size_plot = defaultdict(lambda: defaultdict(dict))\n",
    "compression_speed_plot = defaultdict(lambda: defaultdict(dict))\n",
    "decompression_speed_plot = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "# Buffer for timing metrics, ignore the first and last 'buffer' measurements\n",
    "buffer = 3\n",
    "\n",
    "# Track all fpaths even if redundant to make it easier to datamine and grab specific images, e.g.\n",
    "# high filesize but low PSNR images (hard to compress).\n",
    "all_fpaths = []\n",
    "all_psnrs = []\n",
    "all_sizes_b = []\n",
    "all_qs = []\n",
    "all_methods = []\n",
    "\n",
    "for (fmt, quality, method), (fpaths, enc_t, dec_t, psnrs, ssims, sizes_b) in results.items():\n",
    "    assert quality not in plot\n",
    "    enc_t_b = enc_t[buffer:-buffer]\n",
    "    dec_t_b = dec_t[buffer:-buffer]\n",
    "    decompression_speed_plot[fmt][method][quality] = np.mean(dec_t_b), np.std(dec_t_b)\n",
    "    compression_speed_plot[fmt][method][quality] = np.mean(enc_t_b), np.std(enc_t_b)\n",
    "    \n",
    "    plot[fmt][method][quality] = np.mean(psnrs), np.std(psnrs)\n",
    "    size_plot[fmt][method][quality] = np.mean(sizes_b), np.std(sizes_b)\n",
    "\n",
    "    all_fpaths += fpaths\n",
    "    all_sizes_b += sizes_b\n",
    "    all_psnrs += psnrs\n",
    "    all_qs += [quality] * len(psnrs)\n",
    "    all_methods += [method] * len(psnrs)\n",
    "    \n",
    "    \n",
    "all_sizes_b = np.array(all_sizes_b)\n",
    "all_psnrs = np.array(all_psnrs)\n",
    "all_qs = np.array(all_qs)\n",
    "all_methods = np.array(all_methods)\n",
    "    \n",
    "plt.figure()\n",
    "for fmt in plot:\n",
    "    for method in plot[fmt]:\n",
    "        xx, yy, yerr = [], [], []\n",
    "        for q, (mean_psnr, std) in plot[fmt][method].items():\n",
    "            xx.append(q)\n",
    "            yy.append(mean_psnr)\n",
    "            yerr.append(std)\n",
    "\n",
    "        label = f\"Method: {method} @ {fmt}\"\n",
    "        m = '' if fmt == \"webp\" else \"^\"\n",
    "        if method == 2:\n",
    "            # For debug\n",
    "            m = 'o'\n",
    "    #     plt.errorbar(xx, yy, yerr=yerr, capsize=10, label=label)\n",
    "        plt.plot(xx, yy, label=label, marker=m)\n",
    "       \n",
    "\n",
    "\n",
    "plt.xlabel(\"WebP quality parameter\")\n",
    "plt.ylabel(\"Resulting mean PSNR over dataset\")\n",
    "# plt.ylim(30, 50)\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "\n",
    "plt.figure()\n",
    "for fmt in size_plot:\n",
    "    for method in size_plot[fmt]:\n",
    "        xx, yy, yerr = [], [], []\n",
    "        for q, (mean_sz, std) in size_plot[fmt][method].items():\n",
    "            xx.append(q)\n",
    "            yy.append(mean_sz/1024)\n",
    "            yerr.append(std/1024)\n",
    "        label = f\"Format: {fmt}, Method: {method}\"\n",
    "        m = '' if fmt == \"webp\" else \"^\"\n",
    "    #     plt.errorbar(xx, yy, yerr=yerr, capsize=10, label=label)\n",
    "        plt.plot(xx, yy, label=label, marker=m)\n",
    "        \n",
    "plt.xlabel(\"WebP quality parameter\")\n",
    "plt.ylabel(\"File size, KiB\")\n",
    "plt.ylim(0, 1024)\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for fmt in compression_speed_plot:\n",
    "    for method in compression_speed_plot[fmt]:\n",
    "        xx, yy, yerr = [], [], []\n",
    "        for q, (mean_sz, std) in compression_speed_plot[fmt][method].items():\n",
    "            xx.append(q)\n",
    "            yy.append(mean_sz * 1000)\n",
    "            yerr.append(std * 1000)\n",
    "        label = f\"Method: {method}, fmt = {fmt}\"\n",
    "        m = '' if fmt == \"webp\" else \"^\"\n",
    "#         plt.errorbar(xx, yy, yerr=yerr, capsize=10, label=label, marker=m)\n",
    "        plt.plot(xx, yy, label=label, marker=m)\n",
    "        \n",
    "plt.xlabel(\"WebP quality parameter\")\n",
    "plt.ylabel(\"Compression speed (ms)\")\n",
    "\n",
    "plt.ylim(0, 300)\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()\n",
    "\n",
    "#\n",
    "# Space as a function of method (WebP-specific)\n",
    "#\n",
    "plt.figure()\n",
    "for compression_level in size_plot[\"webp\"][3]:\n",
    "    for fmt in [\"webp\"]:\n",
    "        xx, yy, yerr = [], [], []\n",
    "        for method in size_plot[fmt]:\n",
    "            mean_sz, std = size_plot[fmt][method][compression_level]\n",
    "            xx.append(method)\n",
    "            yy.append(mean_sz / 1024)\n",
    "            yerr.append(std / 1024)\n",
    "\n",
    "        label = f\"Format: {fmt}, Quality: {compression_level}\"\n",
    "        plt.errorbar(xx, yy, yerr=yerr, capsize=10, label=label)\n",
    "\n",
    "# TODO(andrei): Roughly map method to time factor (absolute difference depends on quality)\n",
    "plt.xlabel(\"Method (i.e. computational budget)\")\n",
    "plt.ylabel(\"Mean size (KiB)\")\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plt.figure()\n",
    "for fmt in decompression_speed_plot:\n",
    "    for method in decompression_speed_plot[fmt]:\n",
    "        if fmt == \"jpeg\" and method != -1:\n",
    "            continue\n",
    "            \n",
    "        xx, yy, yerr = [], [], []\n",
    "        for q, (mean_sz, std) in decompression_speed_plot[fmt][method].items():\n",
    "            xx.append(q)\n",
    "            yy.append(mean_sz * 1000)\n",
    "            yerr.append(std * 1000)\n",
    "        label = f\"Method: {fmt} / {method}\"\n",
    "#         plt.errorbar(xx, yy, yerr=yerr, capsize=10, label=label)\n",
    "        m = '' if fmt == \"webp\" else \"^\"\n",
    "        plt.plot(xx, yy, label=label, marker=m)\n",
    "        \n",
    "plt.xlabel(\"WebP / JPEG quality parameter\")\n",
    "plt.ylabel(\"Decompression time (ms)\")\n",
    "\n",
    "plt.ylim(0, 50)\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean size for each PSNR bucket\n",
    "psnr_bins = np.linspace(32, 45, num=10)\n",
    "\n",
    "for q in [100, 95, 90, 85, 80]:\n",
    "    foo = all_psnrs[(all_qs == q) & (all_methods == 3)]\n",
    "    bar = all_sizes_b[(all_qs == q) & (all_methods == 3)]\n",
    "\n",
    "    idxs = np.digitize(foo, psnr_bins)\n",
    "\n",
    "    res = []\n",
    "    res_std = []\n",
    "    for bidx, bin in enumerate(psnr_bins):\n",
    "        res.append(np.mean(bar[idxs == bidx]) / 1024)\n",
    "        res_std.append(np.std(bar[idxs == bidx]) / 1024)\n",
    "\n",
    "    plt.errorbar(psnr_bins, res, yerr=res_std, capsize=8, label=f\"{q = }\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"PSNR\")\n",
    "plt.ylabel(\"Size (KiB)\")\n",
    "plt.ylim(0, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02f9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169f0a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# PSNR vs. File Size\n",
    "#\n",
    "print(len(all_sizes_b))\n",
    "print(len(all_psnrs))\n",
    "c = all_qs\n",
    "ax = plt.scatter(all_psnrs, np.array(all_sizes_b) / 1024, c=c, s=0.1) \n",
    "plt.colorbar(ax)\n",
    "plt.ylim(0, 1024)\n",
    "plt.xlabel(\"PSNR\")\n",
    "plt.ylabel(\"File Size (KiB)\")\n",
    "plt.title(\"Colored by WebP quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc448675",
   "metadata": {},
   "source": [
    "### Some conclusion\n",
    " - initial storage analysis used WebP method 4 at q=85\n",
    " - using JPEG at q85 would increase image space by 50% so we probably can't afford it :(\n",
    "    - current estimate sits at roughly 160TiB conservatively.\n",
    "    - images become ~50% of the storage if q=85 webp\n",
    "    - if we increase image size by 50%, increase total storage by 25%, so ~200TiB, still within the 300TiB\n",
    "    - jpeg at 90 means ~400k images, 100% increase in images, 50% total, so 240TiB, may be a little too much\n",
    "\n",
    " - for webp max compression use at least method = 2\n",
    " - for webp, method = 2 is an outlier in terms of PSNR... either use method = 3 or 0/1\n",
    "     - of course 0/1 will produce larger files, but not by a lot \n",
    "     - prioritize PSNR over very tiny files!\n",
    " - method 3 and 4 are identical in compression speed!\n",
    " - method 2 is way faster than 3, ~2.3x faster\n",
    " - method 1 is is 3x faster than 3 ---> we should use '1'\n",
    "     - storage of method 1 vs. JPEG: 307 --> 250kb, though JPEG PSNR at q=85 is higher\n",
    "     \n",
    "     \n",
    "=> just do method=1 webp at q=90, instead of 2/4 at q=85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342487fb",
   "metadata": {},
   "source": [
    "# Detailed PSNR analysis\n",
    "\n",
    "Maybe look at CDFs? Find outliers where there are huge PSNR gaps between methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "high_file_low_psnr = (all_qs == 85) & (all_methods == 3) & (all_sizes_b > 600) & (all_psnrs < 40)\n",
    "high_file_low_psnr.sum(), \"matches\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
